[druid] 2019-08-17 15:52:53,651 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-08-17 15:52:53,652 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-08-17 15:52:54,412 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2019-08-17 15:52:54,440 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2019-08-17 15:52:54,446 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2019-08-17 15:52:54,466 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:2
   [druid] 2019-08-17 15:52:54,524 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1469517044_0001
   [druid] 2019-08-17 15:52:54,636 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2019-08-17 15:52:54,636 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1469517044_0001
   [druid] 2019-08-17 15:52:54,637 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2019-08-17 15:52:54,640 [Thread-2       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 15:52:54,641 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2019-08-17 15:52:54,669 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2019-08-17 15:52:54,669 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1469517044_0001_m_000000_0
   [druid] 2019-08-17 15:52:54,688 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 15:52:54,692 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 15:52:54,726 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1bf731d2
   [druid] 2019-08-17 15:52:54,730 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/D:/in/rating.json:0+33554432
   [druid] 2019-08-17 15:52:54,769 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-08-17 15:52:54,769 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-08-17 15:52:54,769 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-08-17 15:52:54,769 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-08-17 15:52:54,769 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-08-17 15:52:54,771 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-08-17 15:52:55,591 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-08-17 15:52:55,592 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-08-17 15:52:55,592 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-08-17 15:52:55,592 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 15438679; bufvoid = 104857600
   [druid] 2019-08-17 15:52:55,592 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 24163312(96653248); length = 2051085/6553600
   [druid] 2019-08-17 15:52:55,638 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1469517044_0001 running in uber mode : false
   [druid] 2019-08-17 15:52:55,639 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2019-08-17 15:52:56,113 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-08-17 15:52:56,120 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1469517044_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2019-08-17 15:52:56,127 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-08-17 15:52:56,127 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1469517044_0001_m_000000_0' done.
   [druid] 2019-08-17 15:52:56,127 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1469517044_0001_m_000000_0
   [druid] 2019-08-17 15:52:56,127 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1469517044_0001_m_000001_0
   [druid] 2019-08-17 15:52:56,128 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 15:52:56,128 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 15:52:56,158 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4bbe86fd
   [druid] 2019-08-17 15:52:56,159 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/D:/in/rating.json:33554432+32048203
   [druid] 2019-08-17 15:52:56,166 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-08-17 15:52:56,166 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-08-17 15:52:56,166 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-08-17 15:52:56,166 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-08-17 15:52:56,166 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-08-17 15:52:56,167 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-08-17 15:52:56,640 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 0%
   [druid] 2019-08-17 15:52:56,834 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-08-17 15:52:56,835 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-08-17 15:52:56,835 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-08-17 15:52:56,835 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 14987889; bufvoid = 104857600
   [druid] 2019-08-17 15:52:56,835 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 24264656(97058624); length = 1949741/6553600
   [druid] 2019-08-17 15:52:57,143 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-08-17 15:52:57,149 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1469517044_0001_m_000001_0 is done. And is in the process of committing
   [druid] 2019-08-17 15:52:57,150 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-08-17 15:52:57,150 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1469517044_0001_m_000001_0' done.
   [druid] 2019-08-17 15:52:57,150 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1469517044_0001_m_000001_0
   [druid] 2019-08-17 15:52:57,150 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2019-08-17 15:52:57,151 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2019-08-17 15:52:57,152 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1469517044_0001_r_000000_0
   [druid] 2019-08-17 15:52:57,156 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 15:52:57,156 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 15:52:57,186 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@27952ecf
   [druid] 2019-08-17 15:52:57,188 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@38aed811
   [druid] 2019-08-17 15:52:57,195 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-08-17 15:52:57,196 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1469517044_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-08-17 15:52:57,218 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1469517044_0001_m_000001_0 decomp: 15962763 len: 15962767 to MEMORY
   [druid] 2019-08-17 15:52:57,229 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 15962763 bytes from map-output for attempt_local1469517044_0001_m_000001_0
   [druid] 2019-08-17 15:52:57,230 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 15962763, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->15962763
   [druid] 2019-08-17 15:52:57,234 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1469517044_0001_m_000000_0 decomp: 16464225 len: 16464229 to MEMORY
   [druid] 2019-08-17 15:52:57,244 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 16464225 bytes from map-output for attempt_local1469517044_0001_m_000000_0
   [druid] 2019-08-17 15:52:57,244 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 16464225, inMemoryMapOutputs.size() -> 2, commitMemory -> 15962763, usedMemory ->32426988
   [druid] 2019-08-17 15:52:57,245 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-08-17 15:52:57,245 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 2 / 2 copied.
   [druid] 2019-08-17 15:52:57,245 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-08-17 15:52:57,254 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 2 sorted segments
   [druid] 2019-08-17 15:52:57,254 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 2 segments left of total size: 32426977 bytes
   [druid] 2019-08-17 15:52:57,555 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 2 segments, 32426988 bytes to disk to satisfy reduce memory limit
   [druid] 2019-08-17 15:52:57,555 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 32426990 bytes from disk
   [druid] 2019-08-17 15:52:57,556 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-08-17 15:52:57,556 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 15:52:57,556 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 32426982 bytes
   [druid] 2019-08-17 15:52:57,557 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 2 / 2 copied.
   [druid] 2019-08-17 15:52:57,560 [pool-3-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2019-08-17 15:52:58,185 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1469517044_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2019-08-17 15:52:58,186 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 2 / 2 copied.
   [druid] 2019-08-17 15:52:58,186 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local1469517044_0001_r_000000_0 is allowed to commit now
   [druid] 2019-08-17 15:52:58,186 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local1469517044_0001_r_000000_0' to file:/D:/out/_temporary/0/task_local1469517044_0001_r_000000
   [druid] 2019-08-17 15:52:58,187 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-08-17 15:52:58,187 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1469517044_0001_r_000000_0' done.
   [druid] 2019-08-17 15:52:58,187 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1469517044_0001_r_000000_0
   [druid] 2019-08-17 15:52:58,187 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2019-08-17 15:52:58,641 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2019-08-17 15:52:58,641 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1469517044_0001 completed successfully
   [druid] 2019-08-17 15:52:58,648 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 30
	File System Counters
		FILE: Number of bytes read=229627183
		FILE: Number of bytes written=115882868
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1000208
		Map output records=1000208
		Map output bytes=30426568
		Map output materialized bytes=32426996
		Input split bytes=176
		Combine input records=0
		Combine output records=0
		Reduce input groups=6040
		Reduce shuffle bytes=32426996
		Reduce input records=1000208
		Reduce output records=60400
		Spilled Records=2000416
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=118
		Total committed heap usage (bytes)=2108686336
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=65606731
	File Output Format Counters 
		Bytes Written=1306518
   